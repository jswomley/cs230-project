{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import scipy.misc\n",
    "import tensorflow.keras.layers as tfl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.config.run_functions_eagerly(True)\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "for gpu in gpus:\n",
    "    tf.config.experimental.set_memory_growth(gpu, True)\n",
    "    print(gpu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def downsampling_block(inputs=None, n_filters=32, dropout_prob=0, batchnorm=True):\n",
    "    \"\"\"\n",
    "    Convolutional downsampling block\n",
    "    \n",
    "    Arguments:\n",
    "        inputs -- Input tensor\n",
    "        n_filters -- Number of filters for the convolutional layers\n",
    "        dropout_prob -- Dropout probability\n",
    "        batchnorm -- Boolean determining if batchnorm is applied after the Conv2D layer\n",
    "    Returns: \n",
    "        conv --  Tensor output\n",
    "    \"\"\"\n",
    "\n",
    "    conv = tfl.Conv2D(n_filters,\n",
    "                4,\n",
    "                strides=(2,2),\n",
    "                padding='same',\n",
    "                kernel_initializer=tf.random_normal_initializer(0., 0.02),\n",
    "                use_bias=False)(inputs)\n",
    "    \n",
    "    if batchnorm:\n",
    "        conv = tfl.BatchNormalization()(conv)\n",
    "\n",
    "    if dropout_prob > 0:\n",
    "        conv = tfl.Dropout(dropout_prob)(conv)\n",
    "\n",
    "    conv = tfl.LeakyReLU()(conv)\n",
    "    \n",
    "    return conv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def upsampling_block(expansive_input, contractive_input, n_filters=32, dropout_prob=0, batchnorm=True):\n",
    "    \"\"\"\n",
    "    Convolutional upsampling block\n",
    "    \n",
    "    Arguments:\n",
    "        expansive_input -- Input tensor from previous layer\n",
    "        contractive_input -- Input tensor from previous skip layer\n",
    "        n_filters -- Number of filters for the convolutional layers\n",
    "        dropout_prob -- Probability for Dropout in the Conv2DTranspose layer\n",
    "        batchnorm -- Boolean determining if batchnorm is applied after the Conv2DTranspose layer\n",
    "    Returns: \n",
    "        conv -- Tensor output\n",
    "    \"\"\"\n",
    "\n",
    "    conv = tfl.Conv2DTranspose(\n",
    "                n_filters,\n",
    "                4,\n",
    "                strides=(2,2),\n",
    "                padding='same',\n",
    "                kernel_initializer=tf.random_normal_initializer(0., 0.02),\n",
    "                use_bias=False)(expansive_input)\n",
    "        \n",
    "    if batchnorm:\n",
    "        conv = tfl.BatchNormalization()(conv)\n",
    "\n",
    "    if dropout_prob > 0:\n",
    "        conv = tfl.Dropout(dropout_prob)(conv)\n",
    "\n",
    "    conv = tfl.Concatenate(axis=3)([conv, contractive_input])\n",
    "\n",
    "\n",
    "    conv = tfl.ReLU()(conv)\n",
    "    \n",
    "    return conv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_4\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_3 (InputLayer)           [(None, None, None,  0           []                               \n",
      "                                 3)]                                                              \n",
      "                                                                                                  \n",
      " conv2d_26 (Conv2D)             (None, None, None,   3072        ['input_3[0][0]']                \n",
      "                                64)                                                               \n",
      "                                                                                                  \n",
      " leaky_re_lu_24 (LeakyReLU)     (None, None, None,   0           ['conv2d_26[0][0]']              \n",
      "                                64)                                                               \n",
      "                                                                                                  \n",
      " conv2d_27 (Conv2D)             (None, None, None,   131072      ['leaky_re_lu_24[0][0]']         \n",
      "                                128)                                                              \n",
      "                                                                                                  \n",
      " batch_normalization_34 (BatchN  (None, None, None,   512        ['conv2d_27[0][0]']              \n",
      " ormalization)                  128)                                                              \n",
      "                                                                                                  \n",
      " leaky_re_lu_25 (LeakyReLU)     (None, None, None,   0           ['batch_normalization_34[0][0]'] \n",
      "                                128)                                                              \n",
      "                                                                                                  \n",
      " conv2d_28 (Conv2D)             (None, None, None,   524288      ['leaky_re_lu_25[0][0]']         \n",
      "                                256)                                                              \n",
      "                                                                                                  \n",
      " batch_normalization_35 (BatchN  (None, None, None,   1024       ['conv2d_28[0][0]']              \n",
      " ormalization)                  256)                                                              \n",
      "                                                                                                  \n",
      " leaky_re_lu_26 (LeakyReLU)     (None, None, None,   0           ['batch_normalization_35[0][0]'] \n",
      "                                256)                                                              \n",
      "                                                                                                  \n",
      " conv2d_29 (Conv2D)             (None, None, None,   2097152     ['leaky_re_lu_26[0][0]']         \n",
      "                                512)                                                              \n",
      "                                                                                                  \n",
      " batch_normalization_36 (BatchN  (None, None, None,   2048       ['conv2d_29[0][0]']              \n",
      " ormalization)                  512)                                                              \n",
      "                                                                                                  \n",
      " leaky_re_lu_27 (LeakyReLU)     (None, None, None,   0           ['batch_normalization_36[0][0]'] \n",
      "                                512)                                                              \n",
      "                                                                                                  \n",
      " conv2d_30 (Conv2D)             (None, None, None,   4194304     ['leaky_re_lu_27[0][0]']         \n",
      "                                512)                                                              \n",
      "                                                                                                  \n",
      " batch_normalization_37 (BatchN  (None, None, None,   2048       ['conv2d_30[0][0]']              \n",
      " ormalization)                  512)                                                              \n",
      "                                                                                                  \n",
      " leaky_re_lu_28 (LeakyReLU)     (None, None, None,   0           ['batch_normalization_37[0][0]'] \n",
      "                                512)                                                              \n",
      "                                                                                                  \n",
      " conv2d_31 (Conv2D)             (None, None, None,   4194304     ['leaky_re_lu_28[0][0]']         \n",
      "                                512)                                                              \n",
      "                                                                                                  \n",
      " batch_normalization_38 (BatchN  (None, None, None,   2048       ['conv2d_31[0][0]']              \n",
      " ormalization)                  512)                                                              \n",
      "                                                                                                  \n",
      " leaky_re_lu_29 (LeakyReLU)     (None, None, None,   0           ['batch_normalization_38[0][0]'] \n",
      "                                512)                                                              \n",
      "                                                                                                  \n",
      " conv2d_32 (Conv2D)             (None, None, None,   4194304     ['leaky_re_lu_29[0][0]']         \n",
      "                                512)                                                              \n",
      "                                                                                                  \n",
      " batch_normalization_39 (BatchN  (None, None, None,   2048       ['conv2d_32[0][0]']              \n",
      " ormalization)                  512)                                                              \n",
      "                                                                                                  \n",
      " leaky_re_lu_30 (LeakyReLU)     (None, None, None,   0           ['batch_normalization_39[0][0]'] \n",
      "                                512)                                                              \n",
      "                                                                                                  \n",
      " conv2d_33 (Conv2D)             (None, None, None,   4194304     ['leaky_re_lu_30[0][0]']         \n",
      "                                512)                                                              \n",
      "                                                                                                  \n",
      " batch_normalization_40 (BatchN  (None, None, None,   2048       ['conv2d_33[0][0]']              \n",
      " ormalization)                  512)                                                              \n",
      "                                                                                                  \n",
      " leaky_re_lu_31 (LeakyReLU)     (None, None, None,   0           ['batch_normalization_40[0][0]'] \n",
      "                                512)                                                              \n",
      "                                                                                                  \n",
      " conv2d_transpose_16 (Conv2DTra  (None, None, None,   4194304    ['leaky_re_lu_31[0][0]']         \n",
      " nspose)                        512)                                                              \n",
      "                                                                                                  \n",
      " batch_normalization_41 (BatchN  (None, None, None,   2048       ['conv2d_transpose_16[0][0]']    \n",
      " ormalization)                  512)                                                              \n",
      "                                                                                                  \n",
      " dropout_6 (Dropout)            (None, None, None,   0           ['batch_normalization_41[0][0]'] \n",
      "                                512)                                                              \n",
      "                                                                                                  \n",
      " concatenate_16 (Concatenate)   (None, None, None,   0           ['dropout_6[0][0]',              \n",
      "                                1024)                             'leaky_re_lu_30[0][0]']         \n",
      "                                                                                                  \n",
      " re_lu_14 (ReLU)                (None, None, None,   0           ['concatenate_16[0][0]']         \n",
      "                                1024)                                                             \n",
      "                                                                                                  \n",
      " conv2d_transpose_17 (Conv2DTra  (None, None, None,   8388608    ['re_lu_14[0][0]']               \n",
      " nspose)                        512)                                                              \n",
      "                                                                                                  \n",
      " batch_normalization_42 (BatchN  (None, None, None,   2048       ['conv2d_transpose_17[0][0]']    \n",
      " ormalization)                  512)                                                              \n",
      "                                                                                                  \n",
      " dropout_7 (Dropout)            (None, None, None,   0           ['batch_normalization_42[0][0]'] \n",
      "                                512)                                                              \n",
      "                                                                                                  \n",
      " concatenate_17 (Concatenate)   (None, None, None,   0           ['dropout_7[0][0]',              \n",
      "                                1024)                             'leaky_re_lu_29[0][0]']         \n",
      "                                                                                                  \n",
      " re_lu_15 (ReLU)                (None, None, None,   0           ['concatenate_17[0][0]']         \n",
      "                                1024)                                                             \n",
      "                                                                                                  \n",
      " conv2d_transpose_18 (Conv2DTra  (None, None, None,   8388608    ['re_lu_15[0][0]']               \n",
      " nspose)                        512)                                                              \n",
      "                                                                                                  \n",
      " batch_normalization_43 (BatchN  (None, None, None,   2048       ['conv2d_transpose_18[0][0]']    \n",
      " ormalization)                  512)                                                              \n",
      "                                                                                                  \n",
      " dropout_8 (Dropout)            (None, None, None,   0           ['batch_normalization_43[0][0]'] \n",
      "                                512)                                                              \n",
      "                                                                                                  \n",
      " concatenate_18 (Concatenate)   (None, None, None,   0           ['dropout_8[0][0]',              \n",
      "                                1024)                             'leaky_re_lu_28[0][0]']         \n",
      "                                                                                                  \n",
      " re_lu_16 (ReLU)                (None, None, None,   0           ['concatenate_18[0][0]']         \n",
      "                                1024)                                                             \n",
      "                                                                                                  \n",
      " conv2d_transpose_19 (Conv2DTra  (None, None, None,   8388608    ['re_lu_16[0][0]']               \n",
      " nspose)                        512)                                                              \n",
      "                                                                                                  \n",
      " batch_normalization_44 (BatchN  (None, None, None,   2048       ['conv2d_transpose_19[0][0]']    \n",
      " ormalization)                  512)                                                              \n",
      "                                                                                                  \n",
      " concatenate_19 (Concatenate)   (None, None, None,   0           ['batch_normalization_44[0][0]', \n",
      "                                1024)                             'leaky_re_lu_27[0][0]']         \n",
      "                                                                                                  \n",
      " re_lu_17 (ReLU)                (None, None, None,   0           ['concatenate_19[0][0]']         \n",
      "                                1024)                                                             \n",
      "                                                                                                  \n",
      " conv2d_transpose_20 (Conv2DTra  (None, None, None,   4194304    ['re_lu_17[0][0]']               \n",
      " nspose)                        256)                                                              \n",
      "                                                                                                  \n",
      " batch_normalization_45 (BatchN  (None, None, None,   1024       ['conv2d_transpose_20[0][0]']    \n",
      " ormalization)                  256)                                                              \n",
      "                                                                                                  \n",
      " concatenate_20 (Concatenate)   (None, None, None,   0           ['batch_normalization_45[0][0]', \n",
      "                                512)                              'leaky_re_lu_26[0][0]']         \n",
      "                                                                                                  \n",
      " re_lu_18 (ReLU)                (None, None, None,   0           ['concatenate_20[0][0]']         \n",
      "                                512)                                                              \n",
      "                                                                                                  \n",
      " conv2d_transpose_21 (Conv2DTra  (None, None, None,   1048576    ['re_lu_18[0][0]']               \n",
      " nspose)                        128)                                                              \n",
      "                                                                                                  \n",
      " batch_normalization_46 (BatchN  (None, None, None,   512        ['conv2d_transpose_21[0][0]']    \n",
      " ormalization)                  128)                                                              \n",
      "                                                                                                  \n",
      " concatenate_21 (Concatenate)   (None, None, None,   0           ['batch_normalization_46[0][0]', \n",
      "                                256)                              'leaky_re_lu_25[0][0]']         \n",
      "                                                                                                  \n",
      " re_lu_19 (ReLU)                (None, None, None,   0           ['concatenate_21[0][0]']         \n",
      "                                256)                                                              \n",
      "                                                                                                  \n",
      " conv2d_transpose_22 (Conv2DTra  (None, None, None,   262144     ['re_lu_19[0][0]']               \n",
      " nspose)                        64)                                                               \n",
      "                                                                                                  \n",
      " batch_normalization_47 (BatchN  (None, None, None,   256        ['conv2d_transpose_22[0][0]']    \n",
      " ormalization)                  64)                                                               \n",
      "                                                                                                  \n",
      " concatenate_22 (Concatenate)   (None, None, None,   0           ['batch_normalization_47[0][0]', \n",
      "                                128)                              'leaky_re_lu_24[0][0]']         \n",
      "                                                                                                  \n",
      " re_lu_20 (ReLU)                (None, None, None,   0           ['concatenate_22[0][0]']         \n",
      "                                128)                                                              \n",
      "                                                                                                  \n",
      " conv2d_transpose_23 (Conv2DTra  (None, None, None,   2049       ['re_lu_20[0][0]']               \n",
      " nspose)                        1)                                                                \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 54,421,761\n",
      "Trainable params: 54,410,881\n",
      "Non-trainable params: 10,880\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def Unet(input_shape=[None,None,3], output_channels=1):\n",
    "    \"\"\"\n",
    "    Stage-wise implementation of the architecture of the U-net model.\n",
    "\n",
    "    Arguments:\n",
    "    input_shape -- shape of the images of the dataset\n",
    "    output_channels -- amount of output channels\n",
    "\n",
    "    Returns:\n",
    "    model -- a Model instance in Keras\n",
    "    \"\"\"\n",
    "    \n",
    "    X_input = tfl.Input(input_shape)\n",
    "    skips = []\n",
    "    \n",
    "    X = downsampling_block(X_input, 64, batchnorm=False)\n",
    "    skips.append(X)\n",
    "    X = downsampling_block(X, 128)\n",
    "    skips.append(X)\n",
    "    X = downsampling_block(X, 256)\n",
    "    skips.append(X)\n",
    "    X = downsampling_block(X, 512)\n",
    "    skips.append(X)\n",
    "    X = downsampling_block(X, 512)\n",
    "    skips.append(X)\n",
    "    X = downsampling_block(X, 512)\n",
    "    skips.append(X)\n",
    "    X = downsampling_block(X, 512)\n",
    "    skips.append(X)\n",
    "    X = downsampling_block(X, 512)\n",
    "    skips.append(X)\n",
    "\n",
    "    X = upsampling_block(X, skips[-2], 512, dropout_prob=0.5)\n",
    "    X = upsampling_block(X, skips[-3], 512, dropout_prob=0.5)\n",
    "    X = upsampling_block(X, skips[-4], 512, dropout_prob=0.5)\n",
    "    X = upsampling_block(X, skips[-5], 512)\n",
    "    X = upsampling_block(X, skips[-6], 256)\n",
    "    X = upsampling_block(X, skips[-7], 128)\n",
    "    X = upsampling_block(X, skips[-8], 64)\n",
    "\n",
    "    X = tfl.Conv2DTranspose(output_channels, 4,\n",
    "                            strides=2,\n",
    "                            padding='same',\n",
    "                            kernel_initializer=tf.random_normal_initializer(0., 0.02),\n",
    "                            activation='tanh')(X)\n",
    "\n",
    "    model = tf.keras.Model(inputs = X_input, outputs = X)\n",
    "\n",
    "    return model\n",
    "\n",
    "Generator = Unet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_5\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_image (InputLayer)       [(None, 256, 256, 3  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " target_image (InputLayer)      [(None, 256, 256, 1  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " concatenate_23 (Concatenate)   (None, 256, 256, 4)  0           ['input_image[0][0]',            \n",
      "                                                                  'target_image[0][0]']           \n",
      "                                                                                                  \n",
      " conv2d_34 (Conv2D)             (None, 128, 128, 64  4096        ['concatenate_23[0][0]']         \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " leaky_re_lu_32 (LeakyReLU)     (None, 128, 128, 64  0           ['conv2d_34[0][0]']              \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_35 (Conv2D)             (None, 64, 64, 128)  131072      ['leaky_re_lu_32[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_48 (BatchN  (None, 64, 64, 128)  512        ['conv2d_35[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " leaky_re_lu_33 (LeakyReLU)     (None, 64, 64, 128)  0           ['batch_normalization_48[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_36 (Conv2D)             (None, 32, 32, 256)  524288      ['leaky_re_lu_33[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_49 (BatchN  (None, 32, 32, 256)  1024       ['conv2d_36[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " leaky_re_lu_34 (LeakyReLU)     (None, 32, 32, 256)  0           ['batch_normalization_49[0][0]'] \n",
      "                                                                                                  \n",
      " zero_padding2d_4 (ZeroPadding2  (None, 34, 34, 256)  0          ['leaky_re_lu_34[0][0]']         \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv2d_37 (Conv2D)             (None, 31, 31, 512)  2097152     ['zero_padding2d_4[0][0]']       \n",
      "                                                                                                  \n",
      " batch_normalization_50 (BatchN  (None, 31, 31, 512)  2048       ['conv2d_37[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " leaky_re_lu_35 (LeakyReLU)     (None, 31, 31, 512)  0           ['batch_normalization_50[0][0]'] \n",
      "                                                                                                  \n",
      " zero_padding2d_5 (ZeroPadding2  (None, 33, 33, 512)  0          ['leaky_re_lu_35[0][0]']         \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv2d_38 (Conv2D)             (None, 30, 30, 1)    8193        ['zero_padding2d_5[0][0]']       \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 2,768,385\n",
      "Trainable params: 2,766,593\n",
      "Non-trainable params: 1,792\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def PatchGAN(input_shape=[256, 256, 3], output_channels=1):\n",
    "    \"\"\"\n",
    "    Stage-wise implementation of the architecture of the PatchGAN model.\n",
    "\n",
    "    Arguments:\n",
    "    input_shape -- shape of the images of the dataset\n",
    "    output_channels -- amount of output channels\n",
    "\n",
    "    Returns:\n",
    "    model -- a Model instance in Keras\n",
    "    \"\"\"\n",
    "\n",
    "    initializer = tf.random_normal_initializer(0., 0.02)\n",
    "\n",
    "    inp = tfl.Input(shape=input_shape, name='input_image')\n",
    "    tar = tfl.Input(shape=[input_shape[0], input_shape[1], output_channels], name='target_image')\n",
    "\n",
    "    X = tfl.Concatenate()([inp, tar])\n",
    "\n",
    "    X = downsampling_block(X, 64, batchnorm=False)\n",
    "    X = downsampling_block(X, 128)\n",
    "    X = downsampling_block(X, 256)\n",
    "\n",
    "    X = tfl.ZeroPadding2D()(X)\n",
    "\n",
    "    X = tfl.Conv2D(512, 4, strides=1, kernel_initializer=initializer, use_bias=False)(X)\n",
    "\n",
    "    X = tfl.BatchNormalization()(X)\n",
    "\n",
    "    X = tfl.LeakyReLU()(X)\n",
    "\n",
    "    X = tfl.ZeroPadding2D()(X)\n",
    "\n",
    "    X = tfl.Conv2D(1, 4, strides=1, kernel_initializer=initializer)(X)\n",
    "\n",
    "    return tf.keras.Model(inputs=[inp, tar], outputs=X)\n",
    "\n",
    "Discriminator = PatchGAN()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_object = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n",
    "\n",
    "def discriminator_loss(disc_real_output, disc_generated_output):\n",
    "    \"\"\"\n",
    "    Discriminator loss for the PatchGAN.\n",
    "\n",
    "    Arguments:\n",
    "    disc_real_output -- output of the discriminator on real elevation maps\n",
    "    dis_generated_output -- output of the discriminator on generated maps\n",
    "\n",
    "    Returns:\n",
    "    real_loss + generated_loss -- overall loss of the discriminator\n",
    "    \"\"\"\n",
    "    \n",
    "    real_loss = loss_object(tf.ones_like(disc_real_output), disc_real_output)\n",
    "    generated_loss = loss_object(tf.zeros_like(disc_generated_output), disc_generated_output)\n",
    "\n",
    "    return real_loss + generated_loss\n",
    "\n",
    "def generator_loss(disc_generated_output, gen_output, target):\n",
    "    \"\"\"\n",
    "    Generator loss for the Unet.\n",
    "\n",
    "    Arguments:\n",
    "    disc_generated_output -- output of the discriminator on generated maps\n",
    "    gen_output -- output of the generator on the sample\n",
    "    target -- real elevation map of the sample\n",
    "\n",
    "    Returns:\n",
    "    total_gen_loss -- overall loss of the generator\n",
    "    gan_loss -- loss due to not fooling the discriminator\n",
    "    l1_loss -- loss due to difference to target\n",
    "    \"\"\"\n",
    "\n",
    "    gan_loss = loss_object(tf.ones_like(disc_generated_output), disc_generated_output)\n",
    "    l1_loss = tf.reduce_mean(tf.abs(target - gen_output))\n",
    "\n",
    "    total_gen_loss = gan_loss + (100 * l1_loss)\n",
    "\n",
    "    return total_gen_loss, gan_loss, l1_loss\n",
    "\n",
    "generator_optimizer = tf.keras.optimizers.Adam(0, beta_1=0.5)\n",
    "discriminator_optimizer = tf.keras.optimizers.Adam(0, beta_1=0.5) #2e-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(input_image, target):\n",
    "    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
    "        gen_output = Generator(input_image, training=True)\n",
    "        disc_real_output = Discriminator([input_image, target], training=True)\n",
    "\n",
    "        disc_generated_output = Discriminator([input_image, gen_output], training=True)\n",
    "\n",
    "        gen_loss, gan_loss, l1_loss = generator_loss(disc_generated_output, gen_output, target)\n",
    "        disc_loss = discriminator_loss(disc_real_output, disc_generated_output)\n",
    "\n",
    "    generator_gradients = gen_tape.gradient(gen_loss, Generator.trainable_variables)\n",
    "    discriminator_gradients = disc_tape.gradient(disc_loss, Discriminator.trainable_variables)\n",
    "\n",
    "    generator_optimizer.apply_gradients(zip(generator_gradients, Generator.trainable_variables))\n",
    "    discriminator_optimizer.apply_gradients(zip(discriminator_gradients, Discriminator.trainable_variables))\n",
    "    \n",
    "    return gen_loss, gan_loss, l1_loss, disc_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "def savedata(dataname, *data):\n",
    "    with open(dataname, 'a') as fd:\n",
    "        writer = csv.writer(fd)\n",
    "        writer.writerow(list(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataGenerator(tf.keras.utils.Sequence):\n",
    "  def __init__(self, images, labels, batch_size=128, shuffle=True):\n",
    "    super().__init__()\n",
    "    self.images = images\n",
    "    self.labels = labels\n",
    "    self.batch_size = batch_size\n",
    "    self.shuffle = shuffle\n",
    "    key_array = []\n",
    "    self.key_array = np.arange(self.images.shape[0], dtype=np.uint32)\n",
    "    self.on_epoch_end()\n",
    "\n",
    "  def __len__(self):\n",
    "    return len(self.key_array)//self.batch_size\n",
    "\n",
    "  def __getitem__(self, index):\n",
    "    keys = self.key_array[index*self.batch_size:(index+1)*self.batch_size]\n",
    "    x = np.asarray(self.images[keys], dtype=np.float32)\n",
    "    y = np.asarray(self.labels[keys], dtype=np.float32)\n",
    "    return x, y\n",
    "\n",
    "  def on_epoch_end(self):\n",
    "    if self.shuffle:\n",
    "      self.key_array = np.random.permutation(self.key_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def fit(data_generator, num_epochs):\n",
    "    epoch_times = []\n",
    "    num_batches = len(data_generator)\n",
    "    for epoch in range(num_epochs):\n",
    "        start = time.time()\n",
    "\n",
    "        l1_cost = []\n",
    "        generator_cost = []\n",
    "        gan_cost = []\n",
    "        discriminator_cost = []\n",
    "        for batch in range(num_batches):\n",
    "            x, y = data_generator[batch]\n",
    "            gen_loss, gan_loss, l1_loss, disc_loss = train_step(x, y)\n",
    "            l1_cost.append(l1_loss)\n",
    "            generator_cost.append(gen_loss)\n",
    "            gan_cost.append(gan_loss)\n",
    "            discriminator_cost.append(disc_loss)\n",
    "            \n",
    "        data_generator.on_epoch_end()\n",
    "\n",
    "        l1_cost = np.mean(l1_cost)\n",
    "        generator_cost = np.mean(generator_cost)\n",
    "        gan_cost = np.mean(gan_cost)\n",
    "        discriminator_cost = np.mean(discriminator_cost)\n",
    "      \n",
    "        savedata(\"./training_data.csv\", epoch, l1_cost, generator_cost, gan_cost, discriminator_cost)\n",
    "\n",
    "        epoch_times.append(time.time()-start)\n",
    "\n",
    "        #if (epoch + 1) % 20 == 0 or epoch == 0:\n",
    "            #tf.saved_model.save(Generator, './models/')\n",
    "            #print('Model saved')\n",
    "\n",
    "        print('Time taken for epoch {} is {} seconds. \\n'.format(epoch + 1, epoch_times[-1]))\n",
    "\n",
    "        print('Estimated Time left for remaining {} epochs is {:.2f} sec = {:.2f} hours\\\\n'.format(num_epochs - epoch - 1, \n",
    "        (num_epochs - epoch - 1) * sum(epoch_times) / len(epoch_times), (num_epochs - epoch - 1) * sum(epoch_times) / len(epoch_times)/3600))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "image1 = tf.keras.preprocessing.image.load_img(\"../test_image_5.png\", target_size=(256,256), keep_aspect_ratio=True)\n",
    "image1 = tf.keras.preprocessing.image.img_to_array(image1)\n",
    "image2 = tf.keras.preprocessing.image.load_img(\"../test_image_3.png\", target_size=(256,256), keep_aspect_ratio=True)\n",
    "image2 = tf.keras.preprocessing.image.img_to_array(image2)\n",
    "input_arr = tf.convert_to_tensor([[image1,image1,image2,image2]])\n",
    "input_arr = (input_arr / 127.5) - 1\n",
    "output_arr = tf.random.normal((1,4,256,256,1))\n",
    "dataset = zip(input_arr, output_arr)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
